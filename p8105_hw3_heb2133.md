Homework 3
================

Hannah Briggs (heb2133)

``` r
library(tidyverse)
```

    ## -- Attaching packages --------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

## Problem 1

Load Instacart dataset.

``` r
library(p8105.datasets)
data("instacart")
```

This is an online grocery shopping (Instacart) dataset, that can be used
to explore trends in purchases. It contains 1384617 rows and 15 columns.
Observations are the level of items in orders by customer (i.e., user).
There are customer(user)/order variables – user ID, order ID, order day,
order hour, and days since prior order. In addition, there are item
variables – product ID, product name, aisle name, aisle ID, department
name, and department ID.

Looking at aisles in dataset:

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

There are 134 aisles in the dataset. The top five aisles where the most
items are ordered from are: Fresh vegetables (150,609); Fresh Fruits
(150,473); Packaged vegetables fruits (78,493); Yogurt (55,240); and
Packaged cheese (41,699).

Plot showing number of items ordered in each aisle (limited to aisles
with \> 10000 items ordered):

``` r
instacart %>% 
  count(aisle) %>%
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

![](p8105_hw3_heb2133_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

Table showing the three most popular items in each of the aisles “baking
ingredients”, “dog food care”, and “packaged vegetables fruits”:

``` r
instacart %>% 
  filter(aisle %in%  c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  #Get a ranking for items ordered
  filter(rank < 4) %>% 
  #Get the 3 most popular items
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Table showing the mean hour of the day at which Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week:

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour
  ) %>% 
  rename(
    "sunday" = "0",
    "monday" = "1",
    "tuesday" = "2",
    "wednesday" = "3",
    "thursday" = "4",
    "friday" = "5",
    "saturday" = "6"
  ) %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

| product\_name    |   sunday |   monday |  tuesday | wednesday | thursday |   friday | saturday |
| :--------------- | -------: | -------: | -------: | --------: | -------: | -------: | -------: |
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 |  15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 |  14.25000 | 11.55172 | 12.78431 | 11.93750 |

## Problem 2

Load and tidy accelerometer dataset:

``` r
accel_df = 
  read.csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>% 
  mutate(
    day = factor(day),
    minute = as.numeric(minute),
    weekday_or_weekend = recode(day, 
                             "Monday" = "weekday",
                             "Tuesday" = "weekday",
                             "Wednesday" = "weekday",
                             "Thursday" = "weekday",
                             "Friday" = "weekday",
                             "Saturday" = "weekend",
                             "Sunday" = "weekend")
  ) %>% 
  rename("day_of_observation" = "day_id")
```

This dataset is generated from an accelerometer measuring the daily
activity (i.e., activity measured for each minute of the day) of a 63
year-old male cardiac patient for a period of 5 weeks. Variables include
week number (1-5), number of days into observation (1-35), day of the
week, minute of the day, activity count, and whether observation is on a
weekday or weekend. There are 50400 rows and 6 columns in this dataset.

Trends of daily activity over five weeks:

``` r
accel_df %>% 
  mutate(
    day = factor(day),
    day = forcats::fct_relevel(day, c("Sunday",
                                       "Monday", 
                                       "Tuesday", 
                                       "Wednesday",
                                       "Thursday",
                                       "Friday",
                                       "Saturday"))
  ) %>% 
  group_by(week, day) %>% 
  summarize(daily_activity = sum(activity_count)) %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'week' (override with `.groups` argument)

| week | day       | daily\_activity |
| ---: | :-------- | --------------: |
|    1 | Sunday    |       631105.00 |
|    1 | Monday    |        78828.07 |
|    1 | Tuesday   |       307094.24 |
|    1 | Wednesday |       340115.01 |
|    1 | Thursday  |       355923.64 |
|    1 | Friday    |       480542.62 |
|    1 | Saturday  |       376254.00 |
|    2 | Sunday    |       422018.00 |
|    2 | Monday    |       295431.00 |
|    2 | Tuesday   |       423245.00 |
|    2 | Wednesday |       440962.00 |
|    2 | Thursday  |       474048.00 |
|    2 | Friday    |       568839.00 |
|    2 | Saturday  |       607175.00 |
|    3 | Sunday    |       467052.00 |
|    3 | Monday    |       685910.00 |
|    3 | Tuesday   |       381507.00 |
|    3 | Wednesday |       468869.00 |
|    3 | Thursday  |       371230.00 |
|    3 | Friday    |       467420.00 |
|    3 | Saturday  |       382928.00 |
|    4 | Sunday    |       260617.00 |
|    4 | Monday    |       409450.00 |
|    4 | Tuesday   |       319568.00 |
|    4 | Wednesday |       434460.00 |
|    4 | Thursday  |       340291.00 |
|    4 | Friday    |       154049.00 |
|    4 | Saturday  |         1440.00 |
|    5 | Sunday    |       138421.00 |
|    5 | Monday    |       389080.00 |
|    5 | Tuesday   |       367824.00 |
|    5 | Wednesday |       445366.00 |
|    5 | Thursday  |       549658.00 |
|    5 | Friday    |       620860.00 |
|    5 | Saturday  |         1440.00 |

Looking at this table we can observe potential trends in the patient’s
activity over the 5 weeks. The patient’s activity on weekends seems to
decline over time. For example: His daily activity counts in Week 1 for
Saturday (376,254.0) and Sunday (631,105.0); compared to week 5 Saturday
(1,440.0) and Sunday (138,421.0). His activity, on average, is lower in
the last two weeks of observation, and was highest in the 2nd and 3rd
weeks of observation.

Plot of 24-hour activity for all 35 days of observation:

``` r
accel_week1 =
  accel_df %>% 
    mutate(
    day = factor(day),
    day = forcats::fct_relevel(day, c("Sunday",
                                       "Monday", 
                                       "Tuesday", 
                                       "Wednesday",
                                       "Thursday",
                                       "Friday",
                                       "Saturday"))
  ) %>% 
  filter(week == 1)

accel_week2 = 
  accel_df %>% 
    mutate(
    day = factor(day),
    day = forcats::fct_relevel(day, c("Sunday",
                                       "Monday", 
                                       "Tuesday", 
                                       "Wednesday",
                                       "Thursday",
                                       "Friday",
                                       "Saturday"))
  ) %>% 
  filter(week == 2)

accel_week3 = 
  accel_df %>% 
    mutate(
    day = factor(day),
    day = forcats::fct_relevel(day, c("Sunday",
                                       "Monday", 
                                       "Tuesday", 
                                       "Wednesday",
                                       "Thursday",
                                       "Friday",
                                       "Saturday"))
  ) %>% 
  filter(week == 3)

accel_week4 = 
  accel_df %>% 
    mutate(
    day = factor(day),
    day = forcats::fct_relevel(day, c("Sunday",
                                       "Monday", 
                                       "Tuesday", 
                                       "Wednesday",
                                       "Thursday",
                                       "Friday",
                                       "Saturday"))
  ) %>% 
  filter(week == 4)

accel_week5 = 
  accel_df %>%
    mutate(
    day = factor(day),
    day = forcats::fct_relevel(day, c("Sunday",
                                       "Monday", 
                                       "Tuesday", 
                                       "Wednesday",
                                       "Thursday",
                                       "Friday",
                                       "Saturday"))
  ) %>% 
  filter(week == 5)

ggplot(data = accel_week1,
  aes(x = minute, y = activity_count, color = day)) + 
  geom_smooth(se = FALSE) +
  geom_smooth(data = accel_week2, se = FALSE) +
  geom_smooth(data = accel_week3, se = FALSE) +
  geom_smooth(data = accel_week4, se = FALSE) + 
  geom_smooth(data = accel_week5, se = FALSE) + 
  viridis::scale_color_viridis(
    name = "day",
    discrete = TRUE
  )
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

    ## Warning: Computation failed in `stat_smooth()`:
    ## NA/NaN/Inf in foreign function call (arg 3)

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

    ## Warning: Computation failed in `stat_smooth()`:
    ## NA/NaN/Inf in foreign function call (arg 3)

![](p8105_hw3_heb2133_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

From this plot we can see that daily activity tends to peak roughly
around 600-650 minutes, and minute 1250 of the day. This equates to
activity peaks around roughly 10am, and 9pm. Meaning that in the
early/late afternoon, the patient tends to be less active and relatively
sedentary compared to the rest of the daytime.

## Problem 3

Load NY NOAA dataset.

``` r
library(p8105.datasets)
data("ny_noaa")
```

Looking at missing data:

``` r
ny_noaa %>% count(snow = is.na(snow))
```

    ## # A tibble: 2 x 2
    ##   snow        n
    ##   <lgl>   <int>
    ## 1 FALSE 2213955
    ## 2 TRUE   381221

``` r
ny_noaa %>% count(prcp = is.na(prcp))
```

    ## # A tibble: 2 x 2
    ##   prcp        n
    ##   <lgl>   <int>
    ## 1 FALSE 2449338
    ## 2 TRUE   145838

``` r
ny_noaa %>% count(snwd = is.na(snwd))
```

    ## # A tibble: 2 x 2
    ##   snwd        n
    ##   <lgl>   <int>
    ## 1 FALSE 2003390
    ## 2 TRUE   591786

``` r
ny_noaa %>% count(tmax = is.na(tmax)) 
```

    ## # A tibble: 2 x 2
    ##   tmax        n
    ##   <lgl>   <int>
    ## 1 FALSE 1460818
    ## 2 TRUE  1134358

``` r
ny_noaa %>% count(tmin = is.na(tmin))
```

    ## # A tibble: 2 x 2
    ##   tmin        n
    ##   <lgl>   <int>
    ## 1 FALSE 1460756
    ## 2 TRUE  1134420

This dataset is from the NOAA National Climatic Data Center, containing
data from NY state weather stations from January 1981 to December 2010.
There are 2595176 rows and 7 columns in this dataset. Variables include,
weather station ID, date, precipitation, snowfall and snow depth, and
the max and min temperature.

The dataset is missing data for key variables to the following degree
(number observations = na): Snowfall (381,221), Snowdepth (591,786),
Precipitation (145,838), Tmin (1,134,420), and Tmax (1,460,756).

Data cleaning:

``` r
ny_noaa_clean = 
  ny_noaa %>% 
  separate(date, c("year", "month", "day")) %>% 
  mutate(year = as.numeric(year), 
         day = as.numeric(day),
         month = recode(month, 
                        "1" = "january", 
                        "2" = "february",
                        "3" = "march",
                        "4" = "april",
                        "5" = "may",
                        "6" = "june",
                        "7" = "july",
                        "8" = "august",
                        "9" = "september",
                        "10" = "october",
                        "11" = "november",
                        "12" = "december")
         )
```

“reasonable units”-check in data descrip etc.

snowfall - count, commonly obs values

2panel plot - avg max temp; data manip step then plotting. jan and july
(filter). organize data for avg max temp (group and summ), need ot grop
by station, year, month, and summarize to get avg max temp. panels
(facet, jan and july)

q3: pair plots together - patchwork. plot 1 - tmax/tmin, too much data
for scatterplot, contout or bin or hex plot plot 2 - filter snowfall,
distrib plot (ridge, violin, box = by year)
