---
title: "Homework 3"
output: github_document
---

Hannah Briggs (heb2133)

```{r}
library(tidyverse)
```

## Problem 1

Load Instacart dataset.

```{r}
library(p8105.datasets)
data("instacart")
```

This is an online grocery shopping (Instacart) dataset, that can be used to explore trends in purchases. It contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. Observations are the level of items in orders by customer (i.e., user). There are customer(user)/order variables -- user ID, order ID, order day, order hour, and days since prior order. In addition, there are item variables -- product ID, product name, aisle name, aisle ID, department name, and department ID. 

Looking at aisles in dataset:

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are `r nrow(instacart %>% count(aisle))` aisles in the dataset. The top five aisles where the most items are ordered from are: Fresh vegetables (150,609); Fresh Fruits (150,473); Packaged vegetables fruits (78,493); Yogurt (55,240); and Packaged cheese (41,699).

Plot showing number of items ordered in each aisle (limited to aisles with > 10000 items ordered):

```{r}
instacart %>% 
  count(aisle) %>%
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

Table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”:

```{r}
instacart %>% 
  filter(aisle %in%  c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  #Get a ranking for items ordered
  filter(rank < 4) %>% 
  #Get the 3 most popular items
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour
  ) %>% 
  rename(
    "sunday" = "0",
    "monday" = "1",
    "tuesday" = "2",
    "wednesday" = "3",
    "thursday" = "4",
    "friday" = "5",
    "saturday" = "6"
  ) %>% 
  knitr::kable()
```


## Problem 2

Load and tidy accelerometer dataset:

```{r}
accel_df = 
  read.csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>% 
  mutate(
    day = factor(day),
    minute = as.numeric(minute),
    weekday_weekend = recode(day, 
                             "Monday" = "weekday",
                             "Tuesday" = "weekday",
                             "Wednesday" = "weekday",
                             "Thursday" = "weekday",
                             "Friday" = "weekday",
                             "Saturday" = "weekend",
                             "Sunday" = "weekend")
  )
  
```


Q1:pivot longer - minute of the day, activity count; check if min of day is in numeric or other format, tweak var - useful var names

Q2: group by day, summarize activ counts, make table easier to read, week number and day of week with activ counts. trends? more activ in one week than other? or days? Dow as column-alphabetical order by default, make sure it's in order you want.

Q3: minute x axis, activ count y axis, geom_line, color = day of week, one panel

## Problem 3 

Load NY NOAA dataset. 

```{r}
library(p8105.datasets)
data("ny_noaa")
```

Looking at missing data:
```{r}
ny_noaa %>% count(snow = is.na(snow))
ny_noaa %>% count(prcp = is.na(prcp))
ny_noaa %>% count(snwd = is.na(snwd))
ny_noaa %>% count(tmax = is.na(tmax)) 
ny_noaa %>% count(tmin = is.na(tmin))
```

This dataset is from the NOAA National Climatic Data Center, containing data from NY state weather stations from January 1981 to December 2010. There are `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns in this dataset. Variables include, weather station ID, date, precipitation, snowfall and snow depth, and the max and min temperature.

The dataset is missing data for key variables to the following degree (number observations = na):
Snowfall (381,221), Snowdepth (591,786), Precipitation (145,838), Tmin (1,134,420), and Tmax (1,460,756).

Data cleaning: 
```{r}
ny_noaa_clean = 
  ny_noaa %>% 
  separate(date, c("year", "month", "day")) %>% 
  mutate(year = as.numeric(year), 
         day = as.numeric(day),
         month = recode(month, 
                        "1" = "january", 
                        "2" = "february",
                        "3" = "march",
                        "4" = "april",
                        "5" = "may",
                        "6" = "june",
                        "7" = "july",
                        "8" = "august",
                        "9" = "september",
                        "10" = "october",
                        "11" = "november",
                        "12" = "december")
         )
```


"reasonable units"-check in data descrip etc.

snowfall - count, commonly obs values

2panel plot - avg max temp; data manip step then plotting. jan and july (filter). organize data for avg max temp (group and summ), need ot grop by station, year, month, and summarize to get avg max temp. panels (facet, jan and july)

q3: pair plots together - patchwork. 
plot 1 - tmax/tmin, too much data for scatterplot, contout or bin or hex plot
plot 2 - filter snowfall, distrib plot (ridge, violin, box = by year)